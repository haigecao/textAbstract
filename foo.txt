/* 版权声明：可以任意转载，转载时请务必标明文章原始出处和作者信息 .*/ 



                    文本摘要技术调研

                          

                        CopyMiddle: 张俊林

                         TimeStamp:2010 年9 月  


一．文本摘要值得关注的几个方面

   1.主题覆盖率

        一篇新闻或者文摘往往会包含若干子主题，摘要应该能够覆盖所有这些子主题，至少应该包含主要的子主题； 

   2.冗余尽可能少

        摘要因为是要利用较少的句子来尽可能体现文章主旨信息，所以摘要句子之间的信息冗余应该尽可能小，这样可以满足用尽可能少的信息表达尽可能丰富的文章主旨信息；

   3.摘要流畅性强

       句子之间往往因为会包含代词等指代信息，所以应该避免阅读起来不流畅的问题。  

 

二．不同的摘要任务类型

   1. 抽取式VS合成式

       抽取式文摘：摘要的句子完全从文章正文中进行抽取而成 。基本思路是：按照一定因素给每个句子打分，然后根据句子得分排序，按比例输出得分高的句子作为摘要内容；常见做法是线性组合各种特征，各种特征的权值设定手工指定；

       合成式文摘：不是纯粹从文章中抽取句子，而是对文中的句子片段进行改写，然后进行拼接生成句子集合作为文摘结果；

      从目前研究看，绝大多数实际系统是抽取方式，合成方式目前还是不够成熟，只有少量研究型系统采取这种方法；

 

2. 单文档VS多文档[1,9]

    多文档摘要指的是给定主题相关的K篇文档，通过摘要能够体现这K篇文档的主题信息；

    多文档摘要与单文档摘要相比，有些需要特殊考虑之处，比如：

           冗余度问题：单文档也有这个问题，但是由于K偏文档可能是非常相似的内容，所以这个问题尤其突出；

           句子顺序问题；单文档一般在输出句子的时候，采取按照文章中出现顺序来进行输出；多文档摘要因为句子可能来自不同的文档，所以如何确定顺序是个比较重要的问题。

           压缩率问题：单文档摘要只需按照用户指定的压缩率输出即可，多文档摘要要考虑各自从每个文章中抽取句子比例的问题；

           指代消解问题：单文档也有类似问题，不过由于多文档的代词如果处理不当，可能会指代到另外一篇文章的命名实体，所以对于多文档摘要这个问题尤其突出；

 

3.查询相关VS查询无关[11]

     所谓查询相关式文本摘要，即与一般的摘要不同，希望给定用户查询条件，然后抽取出的文摘摘要不仅要体现文章主旨，还要和用户查询密切相关。所以在对摘要句子重要性进行衡量时，要同时考虑主题性和查询相关性两方面的考虑因素。

  

三．抽取式摘要技术方法分类

（1）非监督方法

     线性组合方法：利用手工构建的评分函数，采取若干重要特征并手工设定特征权重，以此来对句子重要性进行得分计算。

   

    词汇链方法：通过文章中相邻句子的语义相似性来判断文章主题，引入Wordnet等语言资源中的同义词和近义词信息，分析文章中相邻句子的语义相似性。寻找若干最长的词汇链来确定文章包含主题，并依此来构建文摘句子集合；[6,7]

  

    图模型方法：将文章中每个句子作为图中的节点，利用句子之间内容相似性构建图中节点之间的边。构建好文章图后，利用PageRank或者HITS算法来迭代计算图中节点的权值，按照权值大小作为句子重要性的评分依据来对文摘句子进行抽取。[3,4]

 

    子主题分析方法：通过聚类或者语义块分析等手段，发现文章包含的子主题，并从不同的子主题中抽取句子来构造摘要句子集合。LSA，PLSA等方法属于这一类[8,10,12]。

 

（2）监督方法：

   监督学习方法的基本思路如下：[2,5]

      对于句中某个句子，利用分类器来进行二值分类，即0或者1，1代表这个句子可以作为摘要输出句子，0代表这个句子不能作为摘要输出的句子；系统输出被标注为1类型的句子作为文摘输出结果；

      训练集往往通过手工生成的《文章，文摘》对来对分类器进行训练。通过事先定义好的特征集合，将句子映射为特征向量，之后对分类器进行训练生成分类模型。对于新的文章，则根据分类器对于句子的二值分类结果进行文摘输出；

   常用的监督学习方法包括：

     朴素贝叶斯方法(NB)：

     决策树方法：

     HMM方法：

     CRF方法：

     逻辑回归方法(LR)：

     SVM方法

     SVM-HMM方法:

 

四．自动文摘经常使用的特征

 （1）位置因素：句子在文章中出现位置因素，判断句子是否出现在段落首句和尾句，一般段首和段尾是能够体现段落主旨的综合描述句子，尤其是段首句子，如果是则更可能是比较重要的句子；

（2）统计特性：一般通过TF.IDF计算单词权值，统计因素的主旨是发现一些能够表达文章主旨的词汇列表，而那些包含较多这些词汇的句子被认为是能够比较充分体现文章主旨的句子；

（3）文章标题：是否出现过标题中的内容词，标题作为文章的主旨，如果出现过标题中内容词则更可能体现文章主旨；

（4）段落位置：对于新闻类文章而言，往往会在第一段交代很多文章主旨信息，所以距离文章开始位置越近，则一般认为这些句子越重要；

（5）启发词汇：比如能够表达总结的句子，比如“总而言之，综上所述”等等，这种启发词汇列表需要归纳；

（6）句子长度：以一定的长度作为标准，过长的或者过短的会增加惩罚因素；目前研究主要惩罚过短的句子，过长的也应该列入考虑；

    （7）大写单词（英文）：一些大写的单词往往是比较重要的实体或者强调的内容，所以包含大写单词的句子较为重要；

    （8）代词：包含代词的句子因为代词需要指明所指代的实体，需要解决指代消解问题，所以在不能有效解决指代消解问题的情况下，需要对于包含代词的句子进行减分；

    （9）语义关系分析：有些工作是对句子之间的语义关系进行分析，抽取概述性句子，这个速度比较慢，效果也未必很好，但是可以借鉴的思路是：有些详述性的句子是有很明显特征出现的，对于详述性的句子，应该考虑降分； 

     (10)冗余的消除：在选择句子作为候选摘要句子时候，尽可能增加内容的信息含量，尽可能减少相同信息的句子重复出现；所以经常对冗余句子进行消除或者减分操作；

    （11）语义块的切割：将文档切割成语义密切相关的语义段落，之后从语义段落中抽取句子；

 

五．目前方法的效果比较

     目前有些研究工作[2,5]对目前的主流文摘方法效果进行了对比，综合这些结果，可以得出如下一些结论：

      1.对于非监督方法来说，基于HITS的图模型方法明显优于其他方法，

      2.对于监督方法来说，SVM-HMM和CRF方法效果最好，其中SVM-HMM方法在一般测试集合上稍微优于CRF，在难度高的测试集合上效果明显好于CRF方法。这两个方法优于HITS图模型方法，不过优势并非特别明显；

      3.从测试结果来看，方法效果排序如下

        SVM-HMM>CRF>HITS>HMM>SVM>LR>NB>LSA

 

六．可供选择的方法及其各自优缺点分析

     （1）简单特征线性组合方法

       即确定一些主要特征，然后设定特征权重后根据线性组合方式来进行句子打分和排序输出；

      优点：

          方法简单；

          无需训练数据；

          执行速度快；

      缺点：

          由于手工拟合评分函数，只能采取部分主要特征；

          权重设定需要手工设置并不断调试；

          效果一般；

        

（2）基于HITS的图模型方法

   考虑到目前的研究表明，基于HITS的图模型方法是非监督方法中效果最好的，如果采取非监督方法，则优先考虑HITS的图模型方法；

   优点:

     无需训练集合；

     基本与语言和领域无关；

     效果好；

   缺点：

      由于存在任意句子相似性计算和迭代计算，所以运行速度相对比较慢；需要改进速度提出改进方法；

      该方法没有考虑信息冗余的问题，可能需要有针对性的改进；

 

（3）基于CRF或者SVM-HMM的监督学习方法

     目前研究表明，CRF和SVM-HMM在所有监督和非监督方法中是效果最好的，其中SVM-HMM效果略好于CRF，CRF略好于HITS图模型方法；

      所以如果采取监督学习思路，可以考虑CRF或者SVM-HMM的方法；

      优点：

           效果好；

       缺点：

          需要训练数据；

          效果依赖于训练数据质量和领域等方面的情况；

          执行速度慢；尤其是融合HITS模型等复杂特征，需要首先计算复杂特征，所以速度应该是最慢的；

   

 

 

 部分较重要参考文献：

 

[1] .Jie Tangy, Limin Yaoz, and Dewei Chen . Multi-topicbased Query-oriented Summarization.

W.-T.Yih, J. Goodman, L. Vanderwende, and H. Suzuki. Multi-documentsummarization by maximizing informative content-words.In Proceedingsof IJCAI’07, 2007.

[2]  Dou Shen1,Jian-Tao Sun.etc    DocumentSummarization using Conditional Random Fields.  InProceedingsof IJCAI’07, 2007.

 

[3] GunesErkan.  Dragomir R. Radev.  LexRank: Graph-based LexicalCentrality as Salience in   Text Summarization.  Journal of ArtificialIntelligence Research 22 (2004) 457-479

[4] Rada Mihalcea.  Language Independent Extractive Summarization.

[5] LiangdaLi†, Ke Zhou†,Gui-Rong Xue etc  Enhancing Diversity, Coverage and Balance for  Summarization through Structure Learning.  WWW 2009.

[6] GregorySilber and KathleenF. McCoy  EfficientText Summarization Using Lexical Chains.

[7] Barzilay,Regina and Michael Elhadad. Using Lexical Chainsfor Text Summarization. in Proceedings of the IntelligentScalable Text Summarization Workshop(ISTS’97), 1997.

[8] Shanmugasundaram Hariharan   Extraction Based Multi Document Summarization using Single Document  Summary Cluster   Int. J.Advance. Soft Comput. Appl., Vol. 2, No. 1, March 2010

[9] ShanmugasundaramHariharan, "Merging Multi-Document Text Summaries-A Case Study", Journal of Scienceand Technology, Vol.5, No.4,pp.63-74, December 2009.

[10] JinZhang etc  AdaSum: An Adaptive Model for Summarization.  CIKM 2008.

[11] Varadarajan and Hristidis. A System forQuery-Specific Document Summarization CIKM2006.

[12] LeonhardHennig  Topic-based Multi-DocumentSummarization withProbabilistic Latent Semantic Analysis